---
creation date: 2021-09-23 16:03
---
#  Grid Computing Lecture 2
23rd September 2021

## MPI
Message Passing Interface
```
mpirun (Open MPI) 4.1.1

Usage: mpirun [OPTION]...  [PROGRAM]...
Start the given program using Open RTE

-c|-np|--np <arg0>       Number of processes to run
-h|--help <arg0>         This help message
   -n|--n <arg0>         Number of processes to run
-q|--quiet               Suppress helpful messages
-v|--verbose             Be verbose
-V|--version             Print version and exit
```
- Runtime.
- https://stackoverflow.com/questions/18243379/difference-b-w-mpi-tcp-ip/18243600
- Standard for passing messages between processes.
- [[Grid Computing/1#SPMD]].
- **Distributed**: Memory on unique to each processor.
- **Shared**: Memory shared between processors.
- **Hybrid**: Mixture of both.

## OpenMPI C Library
- `MPI_X` prefix to functions.
- Return code format: `MPI_SUCCESS` const.
- `MPI_Init(&argc, &argv)` called at start of program.
	 - Arguments come from `mpirun`. (Num processed to run, etc)
- `MPI_COMM_WORLD`: Parallel context. Idenitifies the global communication context.
	- [[#Communicators]]
### Elements
- Size: number of processes. `MPI_Comm_size(MPI_COMM_WORLD, &size)` (sets size from global context).
- Rank: Identifies each processor.
	- Acquire data using rank ID.
- Processor name `MPI_Get_processor_name`
	- Unique to actual node.
	- From hardware.
- World Time `MPI_Wtime`.
	- 
	
### Communicators
- Can only communicate within the communicator.
- Each process has a rank within, not outside, acts as ID.